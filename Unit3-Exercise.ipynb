{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing \n",
    "### Exercise III\n",
    "` Mauricio Manuel F. Bergancia & Mherlie Joy U. Chavez `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Wikipedia\n",
    "\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import wikipedia\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbtq also commonly seen as lgbt lgbt lgbtq lgbtqia and lgbtqia is an initialism for lesbian gay bisexual transgender and queer or questioning it is an umbrella term originating in the united states broadly referring to all sexualities romantic orientations sex characteristics and gender identities that are not heterosexual heteroromantic cisgender or endosex\n",
      "in the 1990s gay lesbian and bisexual activists adopted the initialism lgb terminology eventually shifted to lgbt as transgender people gained recognition around that time some activists began to reclaim the term queer seeing it as a more radical and inclusive umbrella term though others reject it due to its history as a pejorative in recognition of this the 2010s saw the adoption of lgbtq and other more inclusive variants\n",
      "some versions of the term such as lgbt and lgbtq add a plus sign to represent additional identities not captured within the initialism many further variants exist which a\n"
     ]
    }
   ],
   "source": [
    "# Accessing Wikipedia topic\n",
    "\n",
    "topic = \"lgbt\"\n",
    "\n",
    "# Get the content of a Wikipedia page\n",
    "\n",
    "page = wikipedia.page(topic)\n",
    "text = page.content[:1000]\n",
    "\n",
    "# Remove punctuation from the text\n",
    "text = re.sub(r'[^\\w\\s]', '', text).lower()  # Remove punctuation and make lowercase\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Print the cleaned content of the page\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Probability Models with Laplace Smoothing\n",
    "\n",
    "def bigram_probabilities(tokens, alpha=1):\n",
    "    bigram_counts = Counter(bigrams(tokens))\n",
    "    unigram_counts = Counter(tokens)\n",
    "    \n",
    "    vocab_size = len(unigram_counts)  # Vocabulary size for smoothing\n",
    "    bigram_probs = {\n",
    "        bigram: (count + alpha) / (unigram_counts[bigram[0]] + alpha * vocab_size)\n",
    "        for bigram, count in bigram_counts.items()\n",
    "    }\n",
    "    return bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram Probability Models with Laplace Smoothing\n",
    "\n",
    "def trigram_probabilities(tokens, alpha=1):\n",
    "    trigram_counts = Counter(trigrams(tokens))\n",
    "    bigram_counts = Counter(zip(tokens, tokens[1:]))\n",
    "    \n",
    "    vocab_size = len(bigram_counts)  # Vocabulary size for smoothing\n",
    "    trigram_probs = {\n",
    "        trigram: (count + alpha) / (bigram_counts[(trigram[0], trigram[1])] + alpha * vocab_size)\n",
    "        for trigram, count in trigram_counts.items()\n",
    "    }\n",
    "    return trigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute probability distributions\n",
    "\n",
    "wiki_bigram = bigram_probabilities(tokens)\n",
    "wiki_trigram = trigram_probabilities(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram Perplexity Computation using Log Probabilities\n",
    "\n",
    "def calculate_bigram_perplexity(bigram_probs, test_sentence, alpha=1):\n",
    "    test_tokens = word_tokenize(test_sentence.lower())\n",
    "    test_bigrams = list(bigrams(test_tokens))\n",
    "    \n",
    "    N = len(test_bigrams)\n",
    "    log_prob_sum = 0\n",
    "    vocab_size = len(set(test_tokens))  # Use test set vocab size for smoothing\n",
    "    \n",
    "    for bigram in test_bigrams:\n",
    "        prob = bigram_probs.get(bigram, alpha / (1 + alpha * vocab_size))  # Laplace smoothing for unknown bigrams\n",
    "        log_prob_sum += math.log2(prob)\n",
    "    \n",
    "    return math.pow(2, -log_prob_sum / N) if N > 0 else float('inf')  # Avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram Perplexity Computation using Log Probabilities\n",
    "\n",
    "def calculate_trigram_perplexity(trigram_probs, test_sentence, alpha=1):\n",
    "    test_tokens = word_tokenize(test_sentence.lower())\n",
    "    test_trigrams = list(trigrams(test_tokens))\n",
    "    \n",
    "    N = len(test_trigrams)\n",
    "    log_prob_sum = 0\n",
    "    vocab_size = len(set(test_tokens))\n",
    "    \n",
    "    for trigram in test_trigrams:\n",
    "        prob = trigram_probs.get(trigram, alpha / (1 + alpha * vocab_size))  # Laplace smoothing\n",
    "        log_prob_sum += math.log2(prob)\n",
    "    \n",
    "    return math.pow(2, -log_prob_sum / N) if N > 0 else float('inf')  # Avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentence\n",
    "\n",
    "test_sentence = \"Gender equality means that all people, regardless of their gender, have the same rights, responsibilities, and opportunities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute perplexities\n",
    "\n",
    "bigram_perplexity_score = calculate_bigram_perplexity(wiki_bigram, test_sentence)\n",
    "trigram_perplexity_score = calculate_trigram_perplexity(wiki_trigram, test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model Perplexity -> 18.999999999999996\n",
      "Trigram Model Perplexity -> 18.999999999999996\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "\n",
    "print(\"Bigram Model Perplexity ->\", bigram_perplexity_score)\n",
    "print(\"Trigram Model Perplexity ->\", trigram_perplexity_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
